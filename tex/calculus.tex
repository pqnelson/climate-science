% 44

\chapter{Calculus}


\begin{node}\label{calculus-0000}%
I am going to work in the Eulerian spirit, relying on symbolic
computation for the most part instead of logical rigour. Certainly
rigour has its places, but it obscures rather than enlightens when it
comes to mathematics applied to science.

Rather than lay down the axioms for natural numbers, then construct the
rationals, reals, and finally complex numbers, I am going to just assume
familiarity with these topics. When forced, I will state and prove the
necessary theorems.
\end{node}

\begin{theorem}[Binomial]\label{calculus-000B}%
For any $n\in\NN_{0}$ and $x$, $y\in\CC$, we have
\[(x+y)^{n} = \sum^{n}_{k=0}\binom{n}{k}x^{k}y^{n-k}.\]
\end{theorem}

\section{Differential Calculus in Single Variable}

\begin{node}[Limits, O-notation]\label{calculus-0005}%
\begin{node}\label{calculus-0002}%
The usual way to introduce derivatives is by first introducing
limits. This obscures the notion of a derivative. What we could do
instead is to introduce infinitesimals $\varepsilon\neq0$ such that
$\varepsilon^{2}=0$. But infinitesimals confuse people, apparently.
We could also introduce ``big O'' notation to make infinitesimal
reasoning more rigorous, which is what Knuth recommends.
\end{node}

\begin{definition}\label{calculus-0001}%
We say $f(x)=\bigO(g(x))$ as $x\to a$ if there exists a constant $M$
such that $|f(x)|\leq M|g(x)|$ in some punctured neighborhood of $a$,
i.e., there exists some $\delta>0$ such that $|f(x)|\leq M|g(x)|$ for all $x\in(a-\delta,x+\delta)\setminus\{a\}$.

We say $f(x)=o(g(x))$ as $x\to a$ if $\lim_{x\to a}f(x)/g(x)=0$.
\end{definition}

\begin{example}
As $x-x_{0}\to 0$, a power series $f(x)=\sum^{\infty}_{k=0}a_{k}(x-x_{0})^{k}$
may be approximated as a polynomial of degree $n$ with the rest of the
series swept under the rug of big O (or little o) terms as
\[f(x) = a_{0} + a_{1}(x-x_{0}) + \dots + a_{n}(x-x_{0})^{n} + \bigO\bigl((x-x_{0})^{n+1}\bigr)\]
or
\[f(x) = a_{0} + a_{1}(x-x_{0}) + \dots + a_{n}(x-x_{0})^{n} + o\bigl((x-x_{0})^{n}\bigr).\]
\end{example}

\begin{theorem}\label{calculus-0004}%
\begin{enumerate}
\item $f(x)=\bigO(f(x))$;
\item If $f(x)=o(g(x))$, then $f(x)=\bigO(g(x))$;
\item If $f(x)=\bigO(g(x))$, then $\bigO(f(x))+\bigO(g(x))=\bigO(g(x))$;
\item If $f(x)=\bigO(g(x))$, then $o(f(x))+o(g(x))=o(g(x))$;
\item Let $c\neq0$, then $c\bigO(g(x))=\bigO(g(x))$ and $co(g(x))=o(g(x))$;
\item $\bigO(f(x))\bigO(g(x))=\bigO(f(x)g(x))$;
\item $o(f(x))\bigO(g(x))=o(f(x)g(x))$;
\item If $g(x)=o(1)$, then
  \[\frac{1}{1+o(g(x))}=1+o(g(x))\]
  and
  \[\frac{1}{1+\bigO(g(x))}=1+\bigO(g(x)).\]
\end{enumerate}
\end{theorem}

\begin{theorem}\label{calculus-0003}%
Around $0$ we have:
\begin{enumerate}
\item $x^{a}=\bigO(x^{b})$ for all $b\leq a$, and $x^{a}=o(x^{b})$ for
  all $b<a$;
\item $\bigO(x^{a})+\bigO(x^{b})=\bigO(x^{\min(a,b)})$,
  and $o(x^{a})+o(x^{b})=o(x^{\min(a,b)})$, and
\[\bigO(x^{a})+o(x^{b}) = \begin{cases}o(x^{b}) & \mbox{if }b<a\\
\bigO(x^{a}) & \mbox{if }b\geq a \end{cases}\]
\item $c\bigO(x^{a}) = \bigO(x^{a})$ and $c o(x^{a})=o(x^{a})$;
\item $x^{b}\bigO(x^{a}) = \bigO(x^{a+b})$ and
  $x^{b} o(x^{a})=o(x^{a+b})$;
\item $\bigO(x^{a})\bigO(x^{b}) = \bigO(x^{a+b})$,
  $\bigO(x^{a})o(x^{b}) = o(x^{a+b})$, and
  $o(x^{a})o(x^{b})=o(x^{a+b})$.
\end{enumerate}
\end{theorem}
\end{node}

\begin{definition}\label{calculus-0006}%
Let $f\colon\RR\to\RR$ be a function, let $|\Delta x|\ll1$ be a small
real value. We define the \define{Derivative} of $f$ at $x_{0}\in\RR$ as
the real number $f'(x_{0})$ satisfying
\[f(x_{0}+\Delta x)=f(x_{0})+f'(x_{0})\cdot\Delta x+\bigO\bigl((\Delta x)^{2}\bigr).\]
When $f$ is differentiable on all of $\RR$ (or whatever its domain is),
we can define its derivative $f'(x)$ to be the obvious function
satisfying $f(x+\Delta x)=f(x)+f'(x)\cdot\Delta x+\bigO\bigl((\Delta x)^{2}\bigr)$.
This is the Newtonian notation, the Leibnizian notation is
\begin{equation}
\left.\frac{\D f(x)}{\D x}\right|_{x=a}=f'(a),\quad\mbox{and}\quad\frac{\D f(x)}{\D x}=f'(x).
\end{equation}

\begin{node}[Notation]\label{calculus-000W}%
We write $\Delta x$ for ``a small but finite change in $x$''. We could
write $\Delta f(x)$ for ``a small but finite change in $f(x)$'' and this
would be
\[\Delta f(x) = f(x+\Delta x)-f(x).\]
Then we see that
\[\frac{\Delta f(x)}{\Delta x} = \frac{\D f(x)}{\D x}+\bigO(\Delta x).\]
This gives the intuition that the derivative describes the change in $f$
at $x$. We intuitively imagine $\D$ refers to ``an infinitesimal change in''
[some quantity].
\end{node}

\begin{theorem}[Linearity]\label{calculus-0007}%
Let $f$, $g$ be two real-valued functions defined at a point $x_{0}$,
let $c_{1}$, $c_{2}$ be arbitrary real numbers. Then we have
\[\left.\frac{\D}{\D x}(c_{1}f(x)+c_{2}g(x))\right|_{x=x_{0}}=c_{1}f'(x_{0})+c_{2}g'(x_{0}).\]
\end{theorem}

\begin{theorem}[Product rule]\label{calculus-0008}%
Let $f$, $g$ be two real-valued functions defined at a point $x_{0}$,
then
\[\left.\frac{\D}{\D x}(f(x)g(x))\right|_{x=x_{0}}=f'(x_{0})g(x_{0})+f(x_{0})g'(x_{0}).\]
\end{theorem}

\begin{node}[Power rule]\label{calculus-0009}%
As an immediate corollary, for any $k\in\RR$, we have
\[\frac{\D}{\D x}x^{k}=kx^{k-1}.\]
\end{node}

\begin{node}\label{calculus-000A}%
The product rule and linearity are arguably \emph{the} defining
properties of the derivative. If we were to generalize the notion of a
derivative to other settings, we would want to begin with a linear
operator which obeys the product rule.
\end{node}

\begin{node}[Chain-rule]\label{calculus-000U}%
We have
\[\frac{\D}{\D x}g(f(x))=g'(f(x))f'(x)\]
when $g(f(x))$ is defined.
\end{node}

\begin{corollary}[Quotient rule]\label{calculus-000V}%
We have
\[\frac{\D}{\D x}\frac{f(x)}{g(x)}=\frac{f'(x)g(x)-f(x)g'(x)}{g(x)^{2}}.\]
\end{corollary}

\begin{example}\label{calculus-000C}%
We see that any polynomial
$f(x)=a_{0}+a_{1}x+a_{2}x^{2}+\dots+a_{n}x^{n}$ has its derivative be
\begin{equation*}
f'(x) = a_{1} + 2a_{2}x+\dots+na_{n}x^{n-1}.
\end{equation*}
This follows from linearity and the power rule.
\end{example}
\end{definition}

\begin{definition}\label{calculus-000D}%
We define the \define{Exponential Function} $\exp\colon\RR\to\RR$ by the
power series
\[\exp(x)=\sum^{\infty}_{n=0}\frac{x^{n}}{n!}\]
for any $x\in\RR$. We similarly define \define{Euler's constant} to be
the real number
\[\E=\exp(1).\]
Note that this means
\[\exp(x)=\E^{x},\]
the exponential of $x$ is $\E$ raised to the power of $x$.

\begin{node}\label{calculus-000H}%
Empirically, we find the first $n$ terms of the truncated $\exp(1)$
series to be
\begin{center}
  \begin{tabular}{c|c}
    $n$ & $S_{n}$\\\hline
    $1$ & $2$\\
    $2$ & $2.5$\\
    $3$ & $2.666667$\\
    $5$ & $2.716667$\\
    $8$ & $2.718279$\\
    $9$ & $2.718282$\\
  \end{tabular}
\end{center}
The first seven digits stabilize after $n=9$.
\end{node}

\begin{theorem}\label{calculus-000E}%
For any $x$, $y\in\RR$, we have $\exp(x)\exp(y)=\exp(x+y)$.
\end{theorem}
\begin{proof}
Let $a_{n}=x^{n}/n!$ and $b_{k}=y^{k}/k!$, then we have by Cauchy's
product
\[\left(\sum^{\infty}_{n=0}a_{n}\right)\left(\sum^{\infty}_{k=0}b_{k}\right)=\sum^{\infty}_{n=0}c_{n}\]
where
\[c_{n}=\sum^{n}_{\ell=0}\frac{x^{\ell}}{\ell!}\frac{y^{n-\ell}}{(n-\ell)!}.\]
We see
\begin{calculation}
c_{n}
\step{unfold definition of $c_{n}$}
\sum^{n}_{\ell=0}\frac{z^{\ell}}{\ell!}\frac{w^{n-\ell}}{(n-\ell)!}
\step{multiply each summand by $1=n!/n!$}
\sum^{n}_{\ell=0}\frac{n!}{n!}\frac{z^{\ell}}{\ell!}\frac{w^{n-\ell}}{(n-\ell)!}
\step{commutativity of multiplication}
\sum^{n}_{\ell=0}\frac{1}{n!}\frac{n!}{\ell!(n-\ell)!} z^{\ell}w^{n-\ell}
\step{folding the definition of binomial coefficients}
\sum^{n}_{\ell=0}\frac{1}{n!}\binom{n}{\ell} z^{\ell}w^{n-\ell}
\step{distributivity}
\frac{1}{n!}\sum^{n}_{\ell=0}\binom{n}{\ell} z^{\ell}w^{n-\ell}
\step{by binomial theorem}
\frac{1}{n!}(z + w)^{n}.
\end{calculation}
Hence the result.
\end{proof}

\begin{theorem}\label{calculus-000F}
The derivative of the exponential function is the exponential function
\[\frac{\D}{\D x}\exp(x)=\exp(x).\]
\end{theorem}
\begin{proof}
There are multiple ways to prove this. We could use linearity and
compute term-wise derivatives of the power series, to find that we
recover the power series again.

We could also observe that
\begin{calculation}
  \exp(x+\Delta x)
\step{by previous theorem}
  \exp(x)\exp(\Delta x)
\step{unfolding $\exp(\Delta x)$ as power series}
  \exp(x)\left(1 + \Delta x + \bigO\bigl((\Delta x)^{2}\bigr)\right)
\step{distributivity}
  \exp(x)+\exp(x)\,\Delta x+\bigO\bigl((\Delta x)^{2}\bigr),
\end{calculation}
and the result follows by inspecting the coefficient of $\Delta x$.
\end{proof}
\end{definition}

\begin{node}[Logarithm]\label{calculus-000G}%
There are multiple ways to approach the logarithm. We could define it as
the inverse function for the exponential, i.e.,
\[y=\exp(x)\iff \ln(y)=x.\]

\begin{node}\label{calculus-000J}%
Let $b>1$ be some fixed real number. The function $\log_{b}(x)$ can be
specified uniquely by the conditions:
\begin{enumerate}
\item $\log_{b}$ is an increasing function;
\item $\log_{b}$ is defined on the positive reals, and produces positive
  reals as its values;
\item $\log_{b}(b)=1$; and
\item for any $x$, $y\in\RR$ both positive, $\log_{b}(xy)=\log_{b}(x)+\log_{b}(y)$.
\end{enumerate}
Dieudonn\'e proves this in \textit{Foundations of Analysis} (1969) \S4.3.1.
\end{node}

\begin{node}[Notation]\label{calculus-000R}%
When $b=\E$ is the base of the logarithm, then we write $\ln(x):=\log_{\E}(x)$.
In this particular case, we call $\ln(x)$ the \define{Natural Logarithm}.
\end{node}

\begin{lemma}\label{calculus-000L}
For $b>1$ we have $\log_{b}(1)=0$.
\end{lemma}

\begin{proof}
This follows from $\log_{b}(1)=\log_{b}(1\cdot 1)=2\log_{b}(1)$.
\end{proof}

\begin{lemma}\label{calculus-000K}
For $b>1$ and $n\in\QQ$, we have $\log_{b}(b^{n})=n$.
\end{lemma}

\begin{proof}
For $n\in\NN_{0}$, this is obvious. We see that
$\log_{b}(b^{n}b^{-n})=0$ and the product rule for logarithms gives us
$\log_{b}(b^{-n})+n=0$, hence we have the result for $n\in\ZZ$.

For $1=\log_{b}(b)=\log_{b}((b^{1/n})^{n})=n\log_{b}(b^{1/n})$, we
obtain the result for the rationals.
\end{proof}

\begin{theorem}\label{calculus-000M}
For any $x\in\RR$ and $b>1$, we have $\log_{b}(b^{x})=x$.
\end{theorem}

\begin{proof}
Suppose $x\notin\QQ$, since the $x\in\QQ$ case has already been proven
as a lemma.
Consider two sequences of rational numbers $q_{n}$ which is strictly
increasing and $q_{n}<x$, and $r_{n}>x$ is strictly decreasing. Then
since $\log_{b}$ is increasing we must have
$\log_{b}(b^{q_{n}})=q_{n}<\log_{b}(b^{x})<r_{n}=\log_{b}(b^{r_{n}})$. The sandwich
theorem gives the result.
\end{proof}

\begin{proposition}\label{calculus-000Q}
Let $b>1$, $k>1$, and $x\in\RR$ be positive. Then
\[\log_{b}(x)=\frac{\log_{k}(x)}{\log_{k}(b)}.\]
\end{proposition}

\begin{proof}
  We have
\begin{calculation}
\log_{k}(x)
\step{since $x=b^{\log_{b}(x)}$}
\log_{k}(b^{\log_{b}(x)})
\step{law of logarithms $\log_{k}(b^{m})=m\log_{k}(b)$ with $m=\log_{b}(x)$}
\log_{b}(x)\log_{k}(b)
\end{calculation}
Therefore dividing through by $\log_{k}(b)$ gives us the result.
\end{proof}

\begin{proposition}\label{calculus-000N}
Let $b>1$. Then
\[\log_{b}(x+\Delta x)=\log_{b}\left(1 + \frac{\Delta x}{x}\right)+\log_{b}(x)\]
\end{proposition}
This follows by $x(1+(\Delta x)/x)=x+\Delta x$ and the law of logarithms.

\begin{lemma}\label{calculus-000O}
Let $b>1$. Then since $\exp(x^{-1}\Delta x)\approx 1 + x^{-1}\Delta x$,
we would have (discarding quadratic corrections),
\[\log_{b}\left(1 + \frac{\Delta x}{x}\right)=\log_{b}(\exp(x^{-1}\Delta x))=\frac{\Delta x}{x}\log_{b}(\E)\]
\end{lemma}

\begin{theorem}\label{calculus-000P}
Let $b>1$. Then we have
\[\frac{\D}{\D x}\log_{b}(x) = \frac{\log_{b}(e)}{x} = \frac{1}{x\ln(b)}.\]
In particular, this means
\[\frac{\D}{\D x}\ln(x)=\frac{1}{x}.\]
\end{theorem}

This follows from the previous propositions and lemma.

\begin{node}[Logarithmic derivative]\label{calculus-0016}%
We can define a notion of a logarithmic derivative of a function $f(x)$
by
\[\frac{\D}{\D x}\ln f(x)=\frac{1}{f(x)}\frac{\D f(x)}{\D x}.\]
This follows by the chain rule and the derivative of the logarithm.

We also note that
\[\frac{\D f(x)}{\D\ln(x)}=\frac{1}{\D\ln(x)/\D x}\frac{\D f(x)}{\D x}\]
by similar reasoning, plus the inverse function theorem. Really? Let
$y=\ln(x)$, so $x=\exp(y)$, then we'd have:
\[\frac{\D f(\exp(y))}{\D y}=\exp(y)f'(\exp(y))=xf'(x)=\frac{1}{1/x}f'(x),\]
as promised.
\end{node}

\begin{node}\label{calculus-000I}%
We could also begin by consider ``small'' nonzero $\Delta x\neq 0$, i.e., $0<|\Delta x|\ll 1$.
Now take any positive number $a\in\RR$, $a>0$. Compute $a^{\Delta x}$,
what is it? Well, we should expect it to be close to 1, since $a^{0}=1$.
A reasonable hypothesis is that
\begin{equation}
a^{\Delta x} = 1 + m\,\Delta x + \bigO\bigl((\Delta x)^{2}\bigr)
\end{equation}
for some positive constant $m>0$. Rearranging terms, we would find
\begin{equation}
m = \frac{a^{\Delta x}-1}{\Delta x} + \bigO(\Delta x).
\end{equation}
Some empirical examples:
\begin{center}
  \begin{tabular}{c|c|c|c}
    $a$ & $\Delta x$ & $a^{\Delta x}$ & $m$\\\hline
    $2$ & $0.1$ & $1.071773$ & $0.71773$\\
    $2$ & $0.01$ & $1.0069556$ & $0.69556$\\
    $2$ & $10^{-7}$ & $1.0000000693147204$ & $0.693147204$\\\hline
    $3$ & $0.1$ & $1.116123$ & $1.16123$\\
    $3$ & $0.01$ & $1.0110467$ & $1.10467$\\
    $3$ & $10^{-7}$ & $1.000000109861235$ & $1.09861235$\\
  \end{tabular}
\end{center}
So $m$ is ostensibly a function of $a$ and $\Delta x$, i.e., we would
have $m=m(a,\Delta x)$.
We see the values of $m$ seem to stabilize as $\Delta x\to0$.
How does $m$ vary when we change $a$? Well,
\begin{calculation}
  (a+\Delta a)^{\Delta x}
\step{distributivity to factor out $a$}
  a^{\Delta x}\left(1+\frac{\Delta a}{a}\right)^{\Delta x}
\step{binomial series expansion}
  a^{\Delta x}\left(1+\frac{\Delta a}{a}\Delta x + \bigO\bigl((\Delta a)^{2}(\Delta x)\bigr)\right)
\end{calculation}
Then $(a+\Delta a)^{\Delta x}=1+(m + a^{-1}\,\Delta a)\Delta x + \bigO\bigl((\Delta a)^{2}(\Delta x)\bigr)$,
and we can conclude
\begin{equation}
\frac{\D}{\D a}m(a,\Delta x) = \frac{1}{a},
\end{equation}
which is independent of $\Delta x$.

We can also surmise that if $a=1$ we should expect $m(1,\Delta x)=0$. 
This is reasonable since $1^{x}=1$ for all $x\in\RR$, so $1^{\Delta x}=1+0\cdot\Delta x$.

Suppose we have $x=N\,\Delta x$ where $N\gg 1$ is ``big'' and $|\Delta
x|\ll1$ is ``small'', then
\begin{calculation}
  a^{x}
\step{since $x=N\,\Delta x$}
  a^{N\Delta x}
\step{rules of powers}
  (a^{\Delta x})^{N}
\step{defining property of $m$}
  (1 + m\,\Delta x)^{N}
\step{since $\Delta x = x/N$}
  \left(1 + \frac{mx}{N}\right)^{N}
\step{binomial series expansion}
  1 + N\frac{mx}{N} + \frac{N(N-1)}{2}\frac{(mx)^{2}}{N^{2}}
    + \frac{N(N-1)(N-2)}{3!}\frac{(mx)^{3}}{N^{3}} + \dots
\step{arithmetic}
  1 + mx + \frac{N}{N}\frac{(N-1)}{N}\frac{(mx)^{2}}{2!}
    + \frac{N}{N}\frac{(N-1)}{N}\frac{(N-2)}{N}\frac{(mx)^{3}}{3!} + \dots
\step{simplify fractions}
  1 + mx + (1 - N^{-1})\frac{(mx)^{2}}{2!}
    + (1 - N^{-1})(1 - 2\cdot N^{-1})\frac{(mx)^{3}}{3!} + \dots
\step{since $N$ is huge, $N^{-1}\approx0$}
  1 + mx + (1 - 0)\frac{(mx)^{2}}{2!}
    + (1 - 0)(1 - 0)\frac{(mx)^{3}}{3!} + \dots
\end{calculation}
Hence we would infer
\begin{equation}
a^{x} = \sum^{\infty}_{n=0}\frac{(mx)^{n}}{n!} +(\Delta
x)(\mbox{something}) = \exp(m(a,\Delta x)x).
\end{equation}
Taking the $\Delta x\to 0$ limit now gives us $a^{x}=\exp(m(a,0)x)$ and
in particular when $a=\exp(1)$ we would have $m(a,0)=1$.
\end{node}
\end{node}

\begin{node}[Trigonometry]\label{calculus-000S}%
Now, we can use the exponential function \zref{calculus-000D} to
introduce two new functions $\sin(x)$ and $\cos(x)$ defined by
\[\exp(\I x)=\cos(x)+\I\sin(x),\]
where $\I^{2}=-1$.

\begin{node}[Conventions]\label{calculus-000X}%
Sadly, the convention is to write $\sin^{2}(x)=\bigl(\sin(x)\bigr)^{2}$,
and similarly for other positive integer powers of $\sin(x)$, and
likewise for $\cos(x)$. It gets confusing for negative powers, because
$\sin^{-1}(x)$ may refer to the inverse function, or it may refer to
$1/\sin(x)$. I will write $\arcsin(x)$ for the inverse function of
$\sin(x)$ (the convention: ``arc'' prefixes the inverse function for
trigonometric functions) and I will have to write
$\bigl(\sin(x)\bigr)^{-n}=1/\sin^{n}(x)$ for $n\in\NN$.
\end{node}

\begin{lemma}\label{calculus-000T}
We have $\cos(x+y)=\cos(x)\cos(y)-\sin(x)\sin(y)$ and $\sin(x+y)=\cos(x)\sin(y)+\sin(x)\cos(y)$.
\end{lemma}

This follows from $\exp(\I x)\exp(\I y)=\exp(\I(x+y))$.

\begin{lemma}\label{calculus-000Y}%
We have $\sin(-x)=-\sin(x)$ and $\cos(-x)=\cos(x)$.
\end{lemma}

This follows by definition of sine and cosine.

\begin{theorem}\label{calculus-000Z}%
  We have
  \[\frac{\D}{\D x}\cos(x)=-\sin(x)\]
  and
  \[\frac{\D}{\D x}\sin(x)=\cos(x).\]
\end{theorem}
This follows from the definition of the sine and cosine, as well as the
derivative of the exponential function.

\begin{definition}\label{calculus-0010}%
We define \define{Secant} $\sec(x)=1/\cos(x)$, \emph{Cosecant}
$\csc(x)=1/\sin(x)$, \emph{Tangent} $\tan(x)=\sin(x)/\cos(x)$, and
\emph{Cotangent} $\cot(x)=\cos(x)/\sin(x)=1/\tan(x)$.
\end{definition}

\begin{theorem}\label{calculus-0011}%
  We have
  \[\frac{\D}{\D x}\tan(x)=\sec^{2}(x)\]
\end{theorem}

This follows from the quotient rule Theorem~\zref{calculus-000V} and the
derivatives of sine and cosine.

\begin{node}\label{calculus-0012}%
  We have
  \[\frac{\D}{\D x}\sec(x)=\frac{\sin(x)}{\cos^{2}(x)}.\]
\end{node}

Again, the quotient rule and the derivative of cosine gives us this result.

\begin{node}\label{calculus-0013}%
  We have
  \[\frac{\D}{\D x}\csc(x)=\frac{-\cos(x)}{\sin^{2}(x)}.\]
\end{node}

\begin{node}\label{calculus-0014}%
  We have
  \[\frac{\D}{\D x}\ln(\cos(x))=-\tan(x).\]
\end{node}

\begin{proof}
By direct calculation,
\begin{calculation}
  \frac{\D}{\D x}\ln(\cos(x))
  \step{chain rule, derivative of logarithm}
  \frac{1}{\cos(x)}\frac{\D}{\D x}\cos(x)
  \step{derivative of cosine is negative sine}
  \frac{-\sin(x)}{\cos(x)}
\end{calculation}
The result follows by definition of tangent.
\end{proof}

\begin{node}\label{calculus-0015}%
We have
\[\frac{\D}{\D x}\ln(\sin(x))=\cot(x).\]
\end{node}

\begin{proof}
By direct calculation
\begin{calculation}
  \frac{\D}{\D x}\ln(\sin(x))
  \step{chain rule, derivative of logarithm}
  \frac{1}{\sin(x)}\frac{\D}{\D x}\sin(x)
  \step{derivative of sine is cosine}
  \frac{\cos(x)}{\sin(x)}
\end{calculation}
The result follows by definition of tangent and cotangent.
\end{proof}

\begin{definition}\label{calculus-0017}%
We define the 2-argument arctangent function
\begin{equation}
\atan2(y, x) =
\begin{cases}
 \arctan\left(y/x\right) &\mbox{if } x > 0, \\
 \arctan\left(y/x\right) + \pi &\mbox{if } x < 0 \mbox{ and } y \geq 0, \\
 \arctan\left(y/x\right) - \pi &\mbox{if } x < 0 \mbox{ and } y < 0, \\
 +\pi/2 &\mbox{if } x = 0 \mbox{ and } y > 0, \\
 -\pi/2 &\mbox{if } x = 0 \mbox{ and } y < 0, \\
 \mbox{undefined} &\mbox{if } x = 0 \mbox{ and } y = 0.
\end{cases}
\end{equation}
\end{definition}

\end{node} % trig functions